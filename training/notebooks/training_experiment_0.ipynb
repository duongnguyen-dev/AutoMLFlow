{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as ort \n",
    "\n",
    "from configs.config import FEATURE_DIR, MODEL_DIR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from datetime import datetime\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_hdf(str(FEATURE_DIR / 'feature_engineering_1.h5'), 'train')\n",
    "test_df = pd.read_hdf(str(FEATURE_DIR / 'feature_engineering_1.h5'), 'test')\n",
    "val_df = pd.read_hdf(str(FEATURE_DIR / 'feature_engineering_1.h5'), 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_df.drop(columns=[\"loan_status\"]).iloc[:, :].values, train_df[\"loan_status\"].iloc[:].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = test_df.drop(columns=[\"loan_status\"]).iloc[:, :].values, test_df[\"loan_status\"].iloc[:].values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build, Hyperparameters selection and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters = {\n",
    "    \"C\": [1, 10],\n",
    "    \"kernel\": [\"rbf\", \"linear\"],\n",
    "    \"gamma\": [\"scale\", \"auto\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    }
   ],
   "source": [
    "# Create a LinearSVC model\n",
    "model = SVC()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, \n",
    "                           param_grid=hyper_parameters, \n",
    "                           cv=3, # Number of fold \n",
    "                           n_jobs=5,\n",
    "                           verbose=True)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the initial type of the model input\n",
    "initial_type = [('float_input', FloatTensorType([None, X_train.shape[1]]))]\n",
    "\n",
    "# Convert the model to ONNX\n",
    "onnx_model = convert_sklearn(best_model, initial_types=initial_type)\n",
    "\n",
    "# Save the ONNX model to a file\n",
    "onnx.save_model(onnx_model, str(MODEL_DIR / 'training_experiment_1.onnx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model and make prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ONNX Runtime session\n",
    "session = ort.InferenceSession(str(MODEL_DIR / 'training_experiment_1.onnx'))\n",
    "\n",
    "# Prepare the input data for prediction\n",
    "input_name = session.get_inputs()[0].name\n",
    "X_test_onnx = np.array(X_test, dtype=np.float32)\n",
    "\n",
    "# Perform inference\n",
    "y_pred = session.run(None, {input_name: X_test_onnx})[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      3500\n",
      "           1       0.75      0.71      0.73      1000\n",
      "\n",
      "    accuracy                           0.88      4500\n",
      "   macro avg       0.84      0.82      0.83      4500\n",
      "weighted avg       0.88      0.88      0.88      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
